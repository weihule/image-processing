import time
import warnings
import numpy as np
from packaging.version import Version
from typing import Dict, Union, Tuple, Optional
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
from scipy.special import expected


class TrtModel(object):
    def __init__(self,
                 model_path: str,
                 gpu_id: int = 0,
                 verbose: bool = True
                 ):
        self._initialized = False
        self.verbose = verbose
        self.gpu_id = gpu_id
        self.cuda_ctx = None  # æ‰‹åŠ¨ç®¡ç†CUDAä¸Šä¸‹æ–‡

        try:
            cuda.init()
            self.cuda_device = cuda.Device(gpu_id)
            self.cuda_ctx = self.cuda_device.make_context()
            if self.verbose:
                print(f"âœ“ CUDA context created on GPU {gpu_id}")

            self._check_version()

            # åˆ›å»ºLogger
            self.logger = trt.Logger(trt.Logger.WARNING)

            # åŠ è½½Engine
            with open(model_path, 'rb') as frb:
                engine_data = frb.read()
            self.runtime = trt.Runtime(self.logger)
            self.engine = self.runtime.deserialize_cuda_engine(engine_data)
            if self.engine is None:
                raise RuntimeError("ååºåˆ—åŒ–CUDAå¼•æ“å¤±è´¥")

            # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            self.context = self.engine.create_execution_context()
            if self.context is None:
                raise RuntimeError(f"åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡å¤±è´¥")

            # åˆ†æè¾“å…¥è¾“å‡ºä¿¡æ¯
            self._analyze_bindings()

            # æ£€æµ‹åŠ¨æ€ç»´åº¦ï¼ˆç§»é™¤æœªä½¿ç”¨çš„dynamic_dimsï¼‰
            self._check_dynamic_shapes()

            # æ ¹æ®æ˜¯å¦åŠ¨æ€å†³å®šåˆ†é…å†…å­˜ç­–ç•¥
            if self.has_dynamic_shapes:
                if not self.use_new_api:
                    raise RuntimeError(f"TensorRT >= 8.5æ‰æ”¯æŒåŠ¨æ€ç»´åº¦")

                self.device_buffers = {}
                self.host_outputs = {}
                self.current_shapes = {}
                self.current_alloc_sizes = {}  # è®°å½•å½“å‰åˆ†é…çš„å­—èŠ‚å¤§å°ï¼ˆä¼˜åŒ–é‡åˆ†é…åˆ¤æ–­ï¼‰
            else:
                self._allocate_buffers_static()

            # åˆ›å»ºcudaæµ
            self.stream = cuda.Stream()

            # å®Œæˆåˆå§‹åŒ–
            self._initialized = True
            self._print_model_info(model_path)

        except Exception as e:
            self.cleanup()
            raise RuntimeError(f"åˆå§‹åŒ–å¤±è´¥{e}")

    def _check_version(self):
        """æ£€æŸ¥TensorRTç‰ˆæœ¬"""
        trt_version = trt.__version__
        self.use_new_api = Version(trt_version) >= Version('8.5')

        # åŒé‡éªŒè¯
        if self.use_new_api:
            self.use_new_api = hasattr(trt.ICudaEngine, 'get_tensor_name')

        print(f"ğŸ“‹ TensorRT ç‰ˆæœ¬: {trt_version}")

        # æ‰“å°cudaä¿¡æ¯
        try:
            cuda_device = cuda.Device(0)
            device_name = cuda_device.name()
            device_name = (device_name.decode('utf-8', errors='ignore')
                           if isinstance(device_name, bytes) else device_name)
            device_cc = cuda_device.compute_capability()
            print(f"  CUDA Device: {device_name}")
            print(f"  Compute Capability: {device_cc}")

        except Exception as e:
            print(f"  CUDA Info: {e}")

    def _get_binding_info(self, idx: int) -> dict:
        """
        è·å–bindingçš„è¯¦ç»†ä¿¡æ¯
            ä»¥yolo11sä¸ºä¾‹ï¼Œnum_bindingsæ˜¯4ï¼Œå¾—åˆ°çš„infoåˆ†åˆ«æ˜¯
            {'name': 'input', 'shape': (1, 3, 960, 960), 'dtype': <DataType.FLOAT: 0>, 'is_input': True}
            {'name': 'onnx::Reshape_979', 'shape': (1, 144, 120, 120), 'dtype': <DataType.FLOAT: 0>, 'is_input': False}
            {'name': 'onnx::Reshape_1006', 'shape': (1, 144, 60, 60), 'dtype': <DataType.FLOAT: 0>, 'is_input': False}
            {'name': 'onnx::Reshape_1033', 'shape': (1, 144, 30, 30), 'dtype': <DataType.FLOAT: 0>, 'is_input': False}
            {'name': 'output', 'shape': (1, 84, 18900), 'dtype': <DataType.FLOAT: 0>, 'is_input': False}
        """
        info = {}
        if self.use_new_api:
            name = self.engine.get_tensor_name(idx)
            info['name'] = name
            info['shape'] = tuple(self.engine.get_tensor_shape(idx))
            info['dtype'] = self.engine.get_tensor_dtype(idx)
            info['is_input'] = self.engine.get_tensor_mode(idx) == trt.TensorIOMode.INPUT
        else:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", DeprecationWarning)
                info['name'] = self.engine.get_binding_name(idx)
                info['shape'] = tuple(self.engine.get_binding_shape(idx))
                info['dtype'] = self.engine.get_binding_dtype(idx)
                info['is_input'] = self.engine.binding_is_input(idx)
        return info

    def _analyze_bindings(self):
        """åˆ†ææ‰€æœ‰è¾“å…¥è¾“å‡ºçš„ç»‘å®šä¿¡æ¯"""
        self.inputs = {}
        self.outputs = {}
        self.bindings_info = {}

        # num_tensorsæ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œengineæœ‰å‡ ä¸ªè¾“å…¥å’Œè¾“å‡ºï¼Œnum_bindingså°±æ˜¯å¤šå°‘ï¼ˆæƒ³è¦å¯è§†åŒ–å¯ä»¥é€šè¿‡onnxæ ¼å¼æ¥çœ‹ï¼‰
        num_bindings = self.engine.num_io_tensors if self.use_new_api else self.engine.num_bindings

        for i in range(num_bindings):
            binding_info = self._get_binding_info(i)
            name = binding_info['name']
            if binding_info['is_input']:
                self.inputs[name] = binding_info
            else:
                self.outputs[name] = binding_info
            self.bindings_info[name] = binding_info
            self.bindings_info[name]['index'] = i       # ç»™æ¯ä¸ªbinding_infoæ·»åŠ indexç´¢å¼•ä¿¡æ¯

        if not self.use_new_api:
            self.bindings = [None] * num_bindings

        print(f"å‘ç° {len(self.inputs)} ä¸ªè¾“å…¥, {len(self.outputs)} ä¸ªè¾“å‡º")

    def _check_dynamic_shapes(self):
        """æ£€æµ‹åŠ¨æ€ç»´åº¦ï¼ˆç§»é™¤æœªä½¿ç”¨çš„self.dynamic_dimsï¼‰"""
        self.has_dynamic_shapes = False
        self.dynamic_dims = {}  # è®°å½•å“ªäº›tensorçš„å“ªäº›ç»´åº¦æ˜¯åŠ¨æ€çš„

        for name, info in self.bindings_info.items():
            dynamic_axes = []
            for idx, dim in enumerate(['shape']):
                if dim == -1 or dim == 0:
                    dynamic_axes.append(idx)
                    self.has_dynamic_shapes = True
            if dynamic_axes:
                self.dynamic_dims[name] = dynamic_axes
                io_type = "Input" if info['is_input'] else "Output"
                print(f"  âš ï¸  {io_type:6} '{name}'æœ‰åŠ¨æ€ç»´åº¦: {dynamic_axes} åŠ¨æ€å½¢çŠ¶:{info['shape']}")

        if not self.dynamic_dims:
            print("æ²¡æœ‰åŠ¨æ€ç»´åº¦")

    @staticmethod
    def _trt_dtype_to_numpy(trt_dtype):
        """TensorRTæ•°æ®ç±»å‹è½¬Numpyæ•°æ®ç±»å‹"""
        dtype_map = {
            trt.DataType.FLOAT: np.float32,
            trt.DataType.HALF: np.float16,
            trt.DataType.INT8: np.int8,
            trt.DataType.INT32: np.int32,
            trt.DataType.BOOL: np.bool_,
        }
        if hasattr(trt.DataType, 'INT64'):
            dtype_map[trt.DataType.INT64] = np.int64
        if hasattr(trt.DataType, 'FLOAT64'):
            dtype_map[trt.DataType.FLOAT64] = np.float64
        return dtype_map.get(trt_dtype, np.float32)

    def _allocate_buffers_static(self):
        """åˆ†é…GPUå’ŒCPUå†…å­˜ï¼ˆä»…ç”¨äºé™æ€shapeï¼‰
        """
        print("\nğŸ’¾ åˆ†é…é™æ€å†…å­˜...")
        self.device_buffers = {}
        self.host_outputs = {}      # åªä¸ºè¾“å‡ºåˆ†é…hostå†…å­˜

        total_gpu_memory = 0
        total_cpu_memory = 0

        for name, info in self.bindings_info.items():
            np_dtype = self._trt_dtype_to_numpy(info['type'])
            dtype_size = np.dtype(np_dtype).itemsize

            # è®¡ç®—bufferå¤§å°
            buffer_size = int(np.prod(info['shape'])) * dtype_size

            try:
                # åˆ†é…GPUå†…å­˜
                d_buffer = cuda.mem_alloc(buffer_size)
                self.device_buffers[name] = d_buffer
                total_gpu_memory += d_buffer

                # å¯¹äºæ—§APIï¼Œè®¾ç½®bindings
                if not self.use_new_api:
                    self.bindings[info['index']] = int(d_buffer)

                # åªä¸ºè¾“å‡ºåˆ†é…é¡µé”å®šä¸»æœºå†…å­˜ï¼ˆè¾“å…¥ç›´æ¥ä»numpyä¼ è¾“ï¼‰
                if not info['is_input']:
                    self.host_outputs[name] = cuda.pagelocked_empty(info['shape'],
                                                                    dtype=np_dtype)
                    total_cpu_memory += buffer_size

                io_type = "Input" if info['is_input'] else "Output"
                print(f"{io_type:6} {name:30} {str(info['shape']):30} {buffer_size/1024/1024:8.2f} MB")

            except Exception as e:
                raise RuntimeError(f"{name} åˆ†é…ç¼“å†²åŒºå¤±è´¥: {e}")

        print(f"total_gpu_memory: {total_gpu_memory}")
        print(f"total_cpu_memory: {total_cpu_memory}")

    def _allocate_buffers_dynamic(self, actual_shapes: Dict[str, Tuple]):
        """æ ¹æ®å®é™…shapeåŠ¨æ€åˆ†é…å†…å­˜(æœ‰ç¼“å­˜åŠŸèƒ½ï¼Œåªåœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…)"""
        for name, shape in actual_shapes.items():
            info = self.bindings_info[name]
            np_dtype = self._trt_dtype_to_numpy(info['dtype'])
            dtype_size = np.dtype(np_dtype).itemsize

            new_size = int(np.prod(shape)) * dtype_size

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ†é…
            need_realloc = False
            if name not in self.device_buffers:
                need_realloc = True
            elif name in self.current_shapes:
                old_size = int(np.prod(self.current_shapes[name])) * dtype_size
                # åªåœ¨sizeå˜å¤§æ—¶æˆ–å˜å°è¶…è¿‡50%æ—¶é‡æ–°åˆ†é…ï¼ˆå‡å°‘é¢‘ç¹é‡æ–°åˆ†é…ï¼‰
                if new_size > old_size or new_size < old_size*0.5:
                    need_realloc = True
            else:
                need_realloc = True

            if need_realloc:
                # é‡Šæ”¾æ—§buffer
                if name in self.device_buffers and self.device_buffers[name] is not None:
                    try:
                        self.device_buffers[name].free()
                    except Exception as e:
                        print(f"{name} é‡Šæ”¾ç¼“å­˜å¤±è´¥: {e}")

                # é‡æ–°åˆ†é…bufferï¼ˆé¢„ç•™20 % ç©ºé—´æˆ–è‡³å°‘1MBï¼Œå‡å°‘é¢‘ç¹é‡æ–°åˆ†é…ï¼‰
                alloc_size = max(int(new_size*1.2), new_size+1024*1024)

                try:
                    self.device_buffers[name] = cuda.mem_alloc(alloc_size)
                    self.current_shapes[name] = shape
                    io_type = "Input" if info['is_input'] else "Output"
                    print(f"{io_type:6} {name:30} {str(info['shape']):30} {alloc_size/1024/1024:8.2f} MB")
                except cuda.Error as e:
                    raise RuntimeError(f"{name} åˆ†é…GPUæ˜¾å­˜å¤±è´¥: {e}")

            # ä¸ºè¾“å‡ºåˆ†é…é¡µé”å®šå†…å­˜
            if not info['is_input']:
                if name not in self.host_outputs or self.host_outputs[name].shape != shape:
                    try:
                        self.host_outputs[name] = cuda.pagelocked_empty(shape, dtype=np_dtype)
                    except cuda.Error as e:
                        raise RuntimeError(f"{name} åˆ†é…é¡µé”å®šå†…å­˜å¤±è´¥: {e}")

    def _print_model_info(self, model_path: str):
        """æ‰“å°æ¨¡å‹ç›¸ä¿¡ä¿¡æ¯"""
        print(f"\n{'-' * 60}")
        print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        print(f"---- è¾“å…¥èŠ‚ç‚¹: {len(self.inputs)} ----")
        for name, info in self.inputs.items():
            np_dtype = info['dtype']
            trt_dtype = self._trt_dtype_to_numpy(np_dtype)
            print(f"    - {name}")
            print(f"      Shape: {info['shape']}")
            print(f"      Type: {trt_dtype}")
            print(f"      NumPy dtype: {np_dtype}")

        print(f"---- è¾“å‡ºèŠ‚ç‚¹: {len(self.outputs)} ----")
        for name, info in self.outputs.items():
            np_dtype = info['dtype']
            trt_dtype = self._trt_dtype_to_numpy(np_dtype)
            print(f"    - {name}:")
            print(f"      Shape: {info['shape']}")
            print(f"      Type: {trt_dtype}")
            print(f"      NumPy dtype: {np_dtype}")
        print(f"{'-'*60}\n")

    def _call_static(self, input_dict: Dict[str, np.ndarray]) -> Union[np.ndarray, Dict[str, np.ndarray]]:
        """é™æ€shapeæ¨ç†"""
        try:
            for name, data in input_dict.items():
                if name not in self.inputs:
                    raise ValueError(f"æœªçŸ¥è¾“å…¥å: {name}")
                expected_shape = self.inputs[name]['shape']
                expected_dtype = self._trt_dtype_to_numpy(self.inputs[name]['dtype'])

                # æ£€æŸ¥å¹¶è°ƒæ•´shape
                if data.shape != expected_shape:
                    if np.prod(data.shape) == np.prod(expected_shape):
                        data = data.reshape(expected_shape)
                    else:
                        raise ValueError(
                            f"{name} è¾“å…¥å½¢çŠ¶ä¸åŒ¹é…, è¾“å…¥:{data.shape}, æœŸæœ›:{expected_shape}"
                        )
        except Exception as e:
            print(f"é™æ€æ¨ç†æ—¶æŠ¥é”™: {e}")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if not hasattr(self, '__initialized'):
            return

        try:
            pass
        except Exception as e:
            print(f"æ¸…ç†èµ„æºå¤±è´¥ {e}")

def test():
    trt_path = r'D:\workspace\weight_data\pre_weight\yolo11\yolo11l.engine'
    tm = TrtModel(model_path=trt_path)


if __name__ == "__main__":
    test()




